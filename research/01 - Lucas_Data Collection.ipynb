{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "801f03f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import des biblioth√®ques n√©cessaires\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b678ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'API GitHub\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "\n",
    "# Optionnel : Token d'authentification pour augmenter les limites de l'API\n",
    "TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = {\"Authorization\": f\"token {TOKEN}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4c8cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repositories(query=\"\", sort=\"stars\", per_page=30):\n",
    "    \"\"\"\n",
    "    R√©cup√®re les repositories depuis l'API GitHub\n",
    "    \n",
    "    Args:\n",
    "        query (str): Terme de recherche (ex: \"python\", \"machine learning\")\n",
    "        sort (str): Tri par 'stars', 'forks', 'updated'\n",
    "        per_page (int): Nombre de r√©sultats par page (max 100)\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste des repositories\n",
    "    \"\"\"\n",
    "    url = f\"{GITHUB_API_URL}/search/repositories\"\n",
    "    params = {\n",
    "        \"q\": query if query else \"stars:>1000\",  # Par d√©faut, projets avec plus de 1000 √©toiles\n",
    "        \"sort\": sort,\n",
    "        \"order\": \"desc\",\n",
    "        \"per_page\": per_page\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"items\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la requ√™te : {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d2af076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©cup√©ration des projets populaires...\n",
      "Nombre de projets r√©cup√©r√©s : 20\n"
     ]
    }
   ],
   "source": [
    "print(\"R√©cup√©ration des projets populaires...\")\n",
    "repositories = get_repositories(query=\"machine learning\", per_page=20)\n",
    "\n",
    "print(f\"Nombre de projets r√©cup√©r√©s : {len(repositories)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8abd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_repository_releases(owner, repo_name, per_page=100):\n",
    "    \"\"\"\n",
    "    R√©cup√®re TOUTES les releases d'un repository (toutes pages)\n",
    "    \n",
    "    Args:\n",
    "        owner (str): Propri√©taire du repository\n",
    "        repo_name (str): Nom du repository\n",
    "        per_page (int): Nombre de releases par page (max 100)\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste de TOUTES les releases, tri√©es de la plus r√©cente √† la plus ancienne\n",
    "    \"\"\"\n",
    "    url = f\"{GITHUB_API_URL}/repos/{owner}/{repo_name}/releases\"\n",
    "    all_releases = []\n",
    "    page = 1\n",
    "    \n",
    "    print(f\"R√©cup√©ration de toutes les releases pour {owner}/{repo_name}...\")\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            \"per_page\": per_page,\n",
    "            \"page\": page\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            releases = response.json()\n",
    "            \n",
    "            if not releases:  # Plus de releases disponibles\n",
    "                break\n",
    "                \n",
    "            all_releases.extend(releases)\n",
    "            print(f\"  Page {page}: {len(releases)} releases (Total: {len(all_releases)})\")\n",
    "            page += 1\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erreur lors de la r√©cup√©ration des releases page {page}: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Total r√©cup√©r√©: {len(all_releases)} releases\")\n",
    "    if all_releases:\n",
    "        # Afficher la p√©riode couverte\n",
    "        newest = all_releases[0]['published_at'] or all_releases[0]['created_at']\n",
    "        oldest = all_releases[-1]['published_at'] or all_releases[-1]['created_at']\n",
    "        print(f\"P√©riode: {oldest[:10]} ‚Üí {newest[:10]}\")\n",
    "        \n",
    "        # Afficher quelques exemples\n",
    "        print(\"\\nPremi√®res releases:\")\n",
    "        for i, release in enumerate(all_releases[:5]):\n",
    "            date = (release['published_at'] or release['created_at'])[:10]\n",
    "            name = release['name'] or release['tag_name']\n",
    "            print(f\"  {i+1}. {date}: {name}\")\n",
    "        \n",
    "        if len(all_releases) > 5:\n",
    "            print(\"  ...\")\n",
    "    \n",
    "    return all_releases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c42ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7813601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_releases_summary(owner, repo_name):\n",
    "    \"\"\"\n",
    "    Affiche un r√©sum√© de toutes les releases d'un repository\n",
    "    \"\"\"\n",
    "    releases = get_all_repository_releases(owner, repo_name)\n",
    "    \n",
    "    if not releases:\n",
    "        print(f\"Aucune release trouv√©e pour {owner}/{repo_name}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nüìã TOUTES LES RELEASES DE {owner}/{repo_name}:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, release in enumerate(releases, 1):\n",
    "        date = (release['published_at'] or release['created_at'])[:10]\n",
    "        name = release['name'] or release['tag_name']\n",
    "        tag = release['tag_name']\n",
    "        \n",
    "        # Indicateur si c'est une pre-release\n",
    "        status = \"\"\n",
    "        if release.get('prerelease'):\n",
    "            status += \" [PRE-RELEASE]\"\n",
    "        if release.get('draft'):\n",
    "            status += \" [DRAFT]\"\n",
    "        \n",
    "        print(f\"{i:3d}. {date} - {name} ({tag}){status}\")\n",
    "    \n",
    "    return releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository = repositories[0]\n",
    "owner = repository[\"owner\"][\"login\"]\n",
    "repo_name = repository[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3f20ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_releases_by_time_spacing(releases, num_releases=8):\n",
    "    \"\"\"\n",
    "    S√©lectionne les releases avec l'espacement temporel maximum\n",
    "    \n",
    "    Args:\n",
    "        releases (list): Liste de toutes les releases\n",
    "        num_releases (int): Nombre de releases √† s√©lectionner\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste des releases avec espacement temporel maximal, tri√©es du plus ancien au plus r√©cent\n",
    "    \"\"\"\n",
    "    if not releases:\n",
    "        return []\n",
    "    \n",
    "    if len(releases) <= num_releases:\n",
    "        # Pas assez de releases, retourner toutes tri√©es par date\n",
    "        return sorted(releases, key=lambda x: x['published_at'] or x['created_at'])\n",
    "    \n",
    "    # Trier par date (plus ancien en premier)\n",
    "    releases_sorted = sorted(releases, key=lambda x: x['published_at'] or x['created_at'])\n",
    "    \n",
    "    # Convertir les dates en objets datetime\n",
    "    releases_with_dates = []\n",
    "    for release in releases_sorted:\n",
    "        date_str = release['published_at'] or release['created_at']\n",
    "        date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "        releases_with_dates.append((release, date_obj))\n",
    "    \n",
    "    # Algorithme de s√©lection pour maximiser l'espacement temporel\n",
    "    selected = []\n",
    "    \n",
    "    # Toujours prendre la premi√®re release (la plus ancienne)\n",
    "    selected.append(releases_with_dates[0])\n",
    "    \n",
    "    # Calculer la p√©riode totale\n",
    "    total_period_days = (releases_with_dates[-1][1] - releases_with_dates[0][1]).days\n",
    "    \n",
    "    if num_releases == 1:\n",
    "        return [selected[0][0]]\n",
    "    \n",
    "    # Calculer l'intervalle cible pour un espacement optimal\n",
    "    target_interval_days = total_period_days / (num_releases - 1)\n",
    "    \n",
    "    print(f\"P√©riode totale: {total_period_days} jours\")\n",
    "    print(f\"Intervalle cible: {target_interval_days:.1f} jours\")\n",
    "    \n",
    "    # S√©lectionner les releases suivantes en cherchant l'espacement optimal\n",
    "    for i in range(1, num_releases - 1):\n",
    "        target_date = selected[0][1] + timedelta(days=int(i * target_interval_days))\n",
    "        \n",
    "        # Trouver la release la plus proche de la date cible\n",
    "        best_release = None\n",
    "        min_diff = float('inf')\n",
    "        \n",
    "        for release, date_obj in releases_with_dates:\n",
    "            # Ne pas reprendre une release d√©j√† s√©lectionn√©e\n",
    "            if any(r[0]['tag_name'] == release['tag_name'] for r in selected):\n",
    "                continue\n",
    "                \n",
    "            # Calculer la diff√©rence avec la date cible\n",
    "            diff = abs((date_obj - target_date).days)\n",
    "            \n",
    "            if diff < min_diff:\n",
    "                min_diff = diff\n",
    "                best_release = (release, date_obj)\n",
    "        \n",
    "        if best_release:\n",
    "            selected.append(best_release)\n",
    "    \n",
    "    # Toujours prendre la derni√®re release (la plus r√©cente)\n",
    "    if not any(r[0]['tag_name'] == releases_with_dates[-1][0]['tag_name'] for r in selected):\n",
    "        selected.append(releases_with_dates[-1])\n",
    "    \n",
    "    # Trier par date et extraire seulement les releases\n",
    "    selected_sorted = sorted(selected, key=lambda x: x[1])\n",
    "    result = [item[0] for item in selected_sorted]\n",
    "    \n",
    "    # Limiter au nombre demand√©\n",
    "    if len(result) > num_releases:\n",
    "        result = result[:num_releases]\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c16d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_spaced_releases_summary(owner, repo_name, num_releases=8):\n",
    "    \"\"\"\n",
    "    R√©cup√®re les releases avec espacement temporel maximal\n",
    "    \n",
    "    Args:\n",
    "        owner (str): Propri√©taire du repository\n",
    "        repo_name (str): Nom du repository\n",
    "        num_releases (int): Nombre de releases √† s√©lectionner\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste des releases s√©lectionn√©es avec espacement temporel optimal\n",
    "    \"\"\"\n",
    "    print(f\"\\nüéØ S√âLECTION DE {num_releases} RELEASES AVEC ESPACEMENT TEMPOREL MAXIMAL\")\n",
    "    print(f\"Repository: {owner}/{repo_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # R√©cup√©rer toutes les releases\n",
    "    all_releases = get_all_repository_releases(owner, repo_name)\n",
    "    \n",
    "    if not all_releases:\n",
    "        print(f\"Aucune release trouv√©e pour {owner}/{repo_name}\")\n",
    "        return []\n",
    "    \n",
    "\n",
    "     # Filtrer pour exclure les pre-releases et drafts\n",
    "    stable_releases = [release for release in all_releases \n",
    "                      if not release.get('prerelease', False) and not release.get('draft', False)]\n",
    "    \n",
    "    print(f\"Releases totales: {len(all_releases)}\")\n",
    "    print(f\"Releases stables (sans pre-releases/drafts): {len(stable_releases)}\")\n",
    "    \n",
    "    if not stable_releases:\n",
    "        print(\"Aucune release stable trouv√©e\")\n",
    "        return []\n",
    "    # S√©lectionner les releases avec espacement temporel\n",
    "    spaced_releases = select_releases_by_time_spacing(stable_releases, num_releases)\n",
    "    \n",
    "    # Afficher les releases s√©lectionn√©es\n",
    "    print(f\"\\nüìã RELEASES S√âLECTIONN√âES (du plus ancien au plus r√©cent):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, release in enumerate(spaced_releases, 1):\n",
    "        date = (release['published_at'] or release['created_at'])[:10]\n",
    "        name = release['name'] or release['tag_name']\n",
    "        tag = release['tag_name']\n",
    "        \n",
    "        status = \"\"\n",
    "        if release.get('prerelease'):\n",
    "            status += \" [PRE-RELEASE]\"\n",
    "        if release.get('draft'):\n",
    "            status += \" [DRAFT]\"\n",
    "        \n",
    "        print(f\"{i:2d}. {date} - {name} ({tag}){status}\")\n",
    "    \n",
    "    # Calculer et afficher les intervalles temporels r√©els\n",
    "    if len(spaced_releases) > 1:\n",
    "        print(f\"\\nüìä INTERVALLES TEMPORELS R√âALIS√âS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        intervals = []\n",
    "        total_days = 0\n",
    "        \n",
    "        for i in range(1, len(spaced_releases)):\n",
    "            date1 = datetime.fromisoformat((spaced_releases[i-1]['published_at'] or spaced_releases[i-1]['created_at']).replace('Z', '+00:00'))\n",
    "            date2 = datetime.fromisoformat((spaced_releases[i]['published_at'] or spaced_releases[i]['created_at']).replace('Z', '+00:00'))\n",
    "            \n",
    "            interval_days = (date2 - date1).days\n",
    "            interval_months = interval_days / 30.44\n",
    "            intervals.append(interval_days)\n",
    "            total_days += interval_days\n",
    "            \n",
    "            print(f\"  {date1.strftime('%Y-%m-%d')} ‚Üí {date2.strftime('%Y-%m-%d')}: {interval_days:4d} jours ({interval_months:5.1f} mois)\")\n",
    "        \n",
    "        avg_interval = total_days / len(intervals)\n",
    "        min_interval = min(intervals)\n",
    "        max_interval = max(intervals)\n",
    "        \n",
    "        print(f\"\\nStatistiques des intervalles:\")\n",
    "        print(f\"  Moyenne: {avg_interval:6.0f} jours ({avg_interval/30.44:5.1f} mois)\")\n",
    "        print(f\"  Minimum: {min_interval:6d} jours ({min_interval/30.44:5.1f} mois)\")\n",
    "        print(f\"  Maximum: {max_interval:6d} jours ({max_interval/30.44:5.1f} mois)\")\n",
    "        \n",
    "        # P√©riode totale couverte\n",
    "        first_date = datetime.fromisoformat((spaced_releases[0]['published_at'] or spaced_releases[0]['created_at']).replace('Z', '+00:00'))\n",
    "        last_date = datetime.fromisoformat((spaced_releases[-1]['published_at'] or spaced_releases[-1]['created_at']).replace('Z', '+00:00'))\n",
    "        total_period = (last_date - first_date).days\n",
    "        \n",
    "        print(f\"\\nP√©riode totale couverte: {total_period} jours ({total_period/365.25:.1f} ann√©es)\")\n",
    "    \n",
    "    return spaced_releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5287d99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ S√âLECTION DE 8 RELEASES AVEC ESPACEMENT TEMPOREL MAXIMAL\n",
      "Repository: tensorflow/tensorflow\n",
      "================================================================================\n",
      "R√©cup√©ration de toutes les releases pour tensorflow/tensorflow...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Page 1: 100 releases (Total: 100)\n",
      "  Page 2: 100 releases (Total: 200)\n",
      "  Page 3: 19 releases (Total: 219)\n",
      "Total r√©cup√©r√©: 219 releases\n",
      "P√©riode: 2016-02-16 ‚Üí 2025-08-13\n",
      "\n",
      "Premi√®res releases:\n",
      "  1. 2025-08-13: TensorFlow 2.19.1\n",
      "  2. 2025-08-13: TensorFlow 2.20.0\n",
      "  3. 2025-07-28: TensorFlow 2.20.0-rc0\n",
      "  4. 2025-03-11: TensorFlow 2.18.1\n",
      "  5. 2025-03-12: TensorFlow 2.19.0\n",
      "  ...\n",
      "Releases totales: 219\n",
      "Releases stables (sans pre-releases/drafts): 108\n",
      "P√©riode totale: 3465 jours\n",
      "Intervalle cible: 495.0 jours\n",
      "\n",
      "üìã RELEASES S√âLECTIONN√âES (du plus ancien au plus r√©cent):\n",
      "--------------------------------------------------------------------------------\n",
      " 1. 2016-02-16 - TensorFlow 0.6.0 (v0.6.0)\n",
      " 2. 2017-06-30 - TensorFlow 1.2.1 (v1.2.1)\n",
      " 3. 2018-11-05 - TensorFlow 1.12.0 (v1.12.0)\n",
      " 4. 2020-01-26 - TensorFlow 1.15.2 (v1.15.2)\n",
      " 5. 2021-08-10 - TensorFlow 2.5.1 (v2.5.1)\n",
      " 6. 2022-11-18 - TensorFlow 2.11.0 (v2.11.0)\n",
      " 7. 2024-03-08 - TensorFlow 2.15.1 (v2.15.1)\n",
      " 8. 2025-08-13 - TensorFlow 2.20.0 (v2.20.0)\n",
      "\n",
      "üìä INTERVALLES TEMPORELS R√âALIS√âS:\n",
      "--------------------------------------------------\n",
      "  2016-02-16 ‚Üí 2017-06-30:  499 jours ( 16.4 mois)\n",
      "  2017-06-30 ‚Üí 2018-11-05:  493 jours ( 16.2 mois)\n",
      "  2018-11-05 ‚Üí 2020-01-26:  446 jours ( 14.7 mois)\n",
      "  2020-01-26 ‚Üí 2021-08-10:  562 jours ( 18.5 mois)\n",
      "  2021-08-10 ‚Üí 2022-11-18:  464 jours ( 15.2 mois)\n",
      "  2022-11-18 ‚Üí 2024-03-08:  476 jours ( 15.6 mois)\n",
      "  2024-03-08 ‚Üí 2025-08-13:  522 jours ( 17.1 mois)\n",
      "\n",
      "Statistiques des intervalles:\n",
      "  Moyenne:    495 jours ( 16.2 mois)\n",
      "  Minimum:    446 jours ( 14.7 mois)\n",
      "  Maximum:    562 jours ( 18.5 mois)\n",
      "\n",
      "P√©riode totale couverte: 3465 jours (9.5 ann√©es)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/2603983',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/2603983/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/2603983/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v0.6.0',\n",
       "  'id': 2603983,\n",
       "  'author': {'login': 'martinwicke',\n",
       "   'id': 577277,\n",
       "   'node_id': 'MDQ6VXNlcjU3NzI3Nw==',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/577277?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/martinwicke',\n",
       "   'html_url': 'https://github.com/martinwicke',\n",
       "   'followers_url': 'https://api.github.com/users/martinwicke/followers',\n",
       "   'following_url': 'https://api.github.com/users/martinwicke/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/martinwicke/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/martinwicke/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/martinwicke/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/martinwicke/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/martinwicke/repos',\n",
       "   'events_url': 'https://api.github.com/users/martinwicke/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/martinwicke/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'MDc6UmVsZWFzZTI2MDM5ODM=',\n",
       "  'tag_name': 'v0.6.0',\n",
       "  'target_commitish': 'master',\n",
       "  'name': 'TensorFlow 0.6.0',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2016-02-10T20:27:36Z',\n",
       "  'updated_at': '2016-02-16T23:01:20Z',\n",
       "  'published_at': '2016-02-16T23:01:20Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v0.6.0',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v0.6.0',\n",
       "  'body': '### Major Features and Improvements\\n- Python 3.3+ support via changes to python codebase and ability\\n  to specify python version via `./configure`.\\n- Some improvements to GPU performance and memory usage:\\n  [convnet benchmarks](soumith/convnet-benchmarks#66)\\n  roughly equivalent with native cudnn v2 performance.  Improvements mostly due\\n  to moving to 32-bit indices, faster shuffling kernels.  More improvements to\\n  come in later releases.\\n\\n### Bug fixes\\n- Lots of fixes to documentation and tutorials, many contributed\\n  by the public.\\n- 271 closed issues\\n\\n### Backwards-incompatible changes\\n- `tf.nn.fixed_unigram_candidate_sampler` changed its default `distortion`\\n  attribute from 0.0 to 1.0. This was a bug in the original release\\n  that is now fixed.\\n',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/2603983/reactions',\n",
       "   'total_count': 2,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 2,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0}},\n",
       " {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/6887226',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/6887226/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/6887226/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v1.2.1',\n",
       "  'id': 6887226,\n",
       "  'author': {'login': 'av8ramit',\n",
       "   'id': 5588272,\n",
       "   'node_id': 'MDQ6VXNlcjU1ODgyNzI=',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/5588272?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/av8ramit',\n",
       "   'html_url': 'https://github.com/av8ramit',\n",
       "   'followers_url': 'https://api.github.com/users/av8ramit/followers',\n",
       "   'following_url': 'https://api.github.com/users/av8ramit/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/av8ramit/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/av8ramit/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/av8ramit/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/av8ramit/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/av8ramit/repos',\n",
       "   'events_url': 'https://api.github.com/users/av8ramit/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/av8ramit/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'MDc6UmVsZWFzZTY4ODcyMjY=',\n",
       "  'tag_name': 'v1.2.1',\n",
       "  'target_commitish': 'r1.2',\n",
       "  'name': 'TensorFlow 1.2.1',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2017-06-30T01:34:24Z',\n",
       "  'updated_at': '2017-06-30T01:35:02Z',\n",
       "  'published_at': '2017-06-30T01:35:02Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v1.2.1',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v1.2.1',\n",
       "  'body': '# Release 1.2.1\\r\\n\\r\\n## Bug Fixes and Other Changes\\r\\n* Updating markdown version required to >= 2.6.8.\\r\\n* Support tensors as dropout rates again, by removing the min(max(..))'},\n",
       " {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/13841904',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/13841904/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/13841904/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v1.12.0',\n",
       "  'id': 13841904,\n",
       "  'author': {'login': 'goldiegadde',\n",
       "   'id': 43185254,\n",
       "   'node_id': 'MDQ6VXNlcjQzMTg1MjU0',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/43185254?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/goldiegadde',\n",
       "   'html_url': 'https://github.com/goldiegadde',\n",
       "   'followers_url': 'https://api.github.com/users/goldiegadde/followers',\n",
       "   'following_url': 'https://api.github.com/users/goldiegadde/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/goldiegadde/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/goldiegadde/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/goldiegadde/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/goldiegadde/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/goldiegadde/repos',\n",
       "   'events_url': 'https://api.github.com/users/goldiegadde/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/goldiegadde/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'MDc6UmVsZWFzZTEzODQxOTA0',\n",
       "  'tag_name': 'v1.12.0',\n",
       "  'target_commitish': 'r1.12',\n",
       "  'name': 'TensorFlow 1.12.0',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2018-11-02T01:35:10Z',\n",
       "  'updated_at': '2018-11-05T23:30:45Z',\n",
       "  'published_at': '2018-11-05T23:30:45Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v1.12.0',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v1.12.0',\n",
       "  'body': '# Release 1.12.0\\r\\n                                                                          \\r\\n## Major Features and Improvements                                                 \\r\\n* Keras models can now be directly exported to the SavedModel format(`tf.contrib.saved_model.save_keras_model()`) and used with Tensorflow Serving.\\r\\n* Keras models now support evaluating with a `tf.data.Dataset`.                    \\r\\n* TensorFlow binaries are built with XLA support linked in by default.\\r\\n* Ignite Dataset added to contrib/ignite that allows to work with Apache Ignite.\\r\\n                                                                                   \\r\\n## Bug Fixes and Other Changes                                                     \\r\\n                                                                                   \\r\\n* `tf.data`:                                                                         \\r\\n  * `tf.data` users can now represent, get, and set options of TensorFlow input pipelines using `tf.data.Options()`, `tf.data.Dataset.options()`, and `tf.data.Dataset.with_options()` respectively.\\r\\n  * New `tf.data.Dataset.reduce()` API allows users to reduce a finite dataset to a single element using a user-provided reduce function.\\r\\n  * New `tf.data.Dataset.window()` API allows users to create finite windows of input dataset; when combined with the `tf.data.Dataset.reduce()` API, this allows users to implement customized batching.\\r\\n  * All C++ code moves to the `tensorflow::data` namespace.                        \\r\\n  * Add support for `num_parallel_calls` to `tf.data.Dataset.interleave`.          \\r\\n* `tf.contrib`:                                                                    \\r\\n  * Remove `tf.contrib.linalg`. `tf.linalg` should be used instead.                \\r\\n  * Replace any calls to `tf.contrib.get_signature_def_by_key(metagraph_def, signature_def_key)` with `meta_graph_def.signature_def[signature_def_key]`. Catching a ValueError exception thrown by `tf.contrib.get_signature_def_by_key` should be replaced by catching a KeyError exception.\\r\\n* `tf.contrib.data`                                                                \\r\\n  * Deprecate, and replace by tf.data.experimental.                                \\r\\n* Other:                                                                           \\r\\n  * Improved XLA stability and performance.\\r\\n  * Fix single replica TensorBoard summary stats in Cloud ML Engine.\\r\\n  * TPUEstimator: Initialize dataset iterators in parallel.\\r\\n  * Keras on TPU model quality and bug fixes.\\r\\n  * Instead of jemalloc, revert back to using system malloc since it simplifies build and has comparable performance.\\r\\n  * Remove integer types from `tf.nn.softplus` and `tf.nn.softsign` OpDefs. This is a bugfix; these ops were never meant to support integers.\\r\\n  * Allow subslicing Tensors with a single dimension.                              \\r\\n  * Add option to calculate string length in Unicode characters                    \\r\\n  * Add functionality to SubSlice a tensor.                                        \\r\\n  * Add searchsorted (ie lower/upper_bound) op.                                    \\r\\n  * Add model explainability to Boosted Trees.                                     \\r\\n  * Support negative positions for tf.substr                                       \\r\\n  * There was previously a bug in the bijector_impl where the _reduce_jacobian_det_over_event does not handle scalar ILDJ implementations properly.\\r\\n  * In tf eager execution, allow re-entering a GradientTape context                \\r\\n  * Add tf_api_version flag. If --define=tf_api_version=2 flag is passed in, then bazel will build TensorFlow API version 2.0. Note that TensorFlow 2.0 is under active development and has no guarantees at this point.\\r\\n  * Add additional compression options to TfRecordWriter                           \\r\\n  * Performance improvements for regex full match operations.                      \\r\\n  * Replace `tf.GraphKeys.VARIABLES` with `tf.GraphKeys.GLOBAL_VARIABLES`            \\r\\n  * Remove unused dynamic learning rate support.                                   \\r\\n                                                                                   \\r\\n## Thanks to our Contributors                                                      \\r\\n                                                                                   \\r\\nThis release contains contributions from many people at Google, as well as: \\r\\n       \\r\\n(David) Siu-Kei Muk, Ag Ramesh, Anton Dmitriev, Artem Sobolev, Avijit-Nervana, Bairen Yi, Bruno Goncalves, By Shen, candy.dc, Cheng Chen, Clayne Robison, coder3101, Dao Zhang, Elms, Fei Hu, feiquan, Geoffrey Irving, Guozhong Zhuang, hellcom, Hoeseong Kim, imsheridan, Jason Furmanek, Jason Zaman, Jenny Sahng, jiefangxuanyan, Johannes Bannhofer, Jonathan Homer, Koan-Sin Tan, kouml, Loo Rong Jie, Lukas Geiger, manipopopo, Ming Li, Moritz Kr√∂Ger, Naurril, Niranjan Hasabnis, Pan Daoxin, Peng Yu, pengwa, rasmi, Roger Xin, Roland Fernandez, Sami Kama, Samuel Matzek, Sangjung Woo, Sergei Lebedev, Sergii Khomenko, shaohua, Shaohua Zhang, Shujian2015, Sunitha Kambhampati, tomguluson92, Vin√≠Cius Camargo, wangsiyu, weidankong, Wen-Heng (Jack) Chung, William D. Irons, Xin Jin, Yan Facai (È¢úÂèëÊâç), Yanbo Liang, Yash Katariya, Yong Tang, Âú®Âéü‰Ωê‰∏∫'},\n",
       " {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/23133744',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/23133744/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/23133744/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v1.15.2',\n",
       "  'id': 23133744,\n",
       "  'author': {'login': 'tensorflow-jenkins',\n",
       "   'id': 16359713,\n",
       "   'node_id': 'MDQ6VXNlcjE2MzU5NzEz',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/16359713?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/tensorflow-jenkins',\n",
       "   'html_url': 'https://github.com/tensorflow-jenkins',\n",
       "   'followers_url': 'https://api.github.com/users/tensorflow-jenkins/followers',\n",
       "   'following_url': 'https://api.github.com/users/tensorflow-jenkins/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/tensorflow-jenkins/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/tensorflow-jenkins/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/tensorflow-jenkins/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/tensorflow-jenkins/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/tensorflow-jenkins/repos',\n",
       "   'events_url': 'https://api.github.com/users/tensorflow-jenkins/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/tensorflow-jenkins/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'MDc6UmVsZWFzZTIzMTMzNzQ0',\n",
       "  'tag_name': 'v1.15.2',\n",
       "  'target_commitish': 'r1.15',\n",
       "  'name': 'TensorFlow 1.15.2',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2020-01-26T03:57:51Z',\n",
       "  'updated_at': '2020-02-06T18:06:04Z',\n",
       "  'published_at': '2020-01-26T15:02:04Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v1.15.2',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v1.15.2',\n",
       "  'body': '# Release 1.15.2\\r\\n\\r\\nNote that this release no longer has a single pip package for GPU and CPU. Please see #36347 for history and details\\r\\n\\r\\n## Bug Fixes and Other Changes\\r\\n* Fixes a security vulnerability where converting a Python string to a `tf.float16` value produces a segmentation fault ([CVE-2020-5215](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-5215))\\r\\n* Updates `curl` to `7.66.0` to handle [CVE-2019-5482](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5482) and [CVE-2019-5481](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5481)\\r\\n* Updates `sqlite3` to `3.30.01` to handle [CVE-2019-19646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19646), [CVE-2019-19645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19645) and [CVE-2019-16168](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-16168)'},\n",
       " {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/47632052',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/47632052/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/47632052/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v2.5.1',\n",
       "  'id': 47632052,\n",
       "  'author': {'login': 'tensorflow-jenkins',\n",
       "   'id': 16359713,\n",
       "   'node_id': 'MDQ6VXNlcjE2MzU5NzEz',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/16359713?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/tensorflow-jenkins',\n",
       "   'html_url': 'https://github.com/tensorflow-jenkins',\n",
       "   'followers_url': 'https://api.github.com/users/tensorflow-jenkins/followers',\n",
       "   'following_url': 'https://api.github.com/users/tensorflow-jenkins/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/tensorflow-jenkins/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/tensorflow-jenkins/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/tensorflow-jenkins/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/tensorflow-jenkins/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/tensorflow-jenkins/repos',\n",
       "   'events_url': 'https://api.github.com/users/tensorflow-jenkins/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/tensorflow-jenkins/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'MDc6UmVsZWFzZTQ3NjMyMDUy',\n",
       "  'tag_name': 'v2.5.1',\n",
       "  'target_commitish': 'r2.5',\n",
       "  'name': 'TensorFlow 2.5.1',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2021-08-08T20:49:54Z',\n",
       "  'updated_at': '2021-08-10T22:06:20Z',\n",
       "  'published_at': '2021-08-10T22:06:20Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v2.5.1',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v2.5.1',\n",
       "  'body': \"# Release 2.5.1\\r\\n\\r\\nThis release introduces several vulnerability fixes:\\r\\n\\r\\n* Fixes a heap out of bounds access in sparse reduction operations ([CVE-2021-37635](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37635))\\r\\n* Fixes a floating point exception in `SparseDenseCwiseDiv` ([CVE-2021-37636](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37636))\\r\\n* Fixes a null pointer dereference in `CompressElement` ([CVE-2021-37637](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37637))\\r\\n* Fixes a null pointer dereference in `RaggedTensorToTensor` ([CVE-2021-37638](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37638))\\r\\n* Fixes a null pointer dereference and a heap OOB read arising from operations restoring tensors ([CVE-2021-37639](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37639))\\r\\n* Fixes an integer division by 0 in sparse reshaping ([CVE-2021-37640](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37640))\\r\\n* Fixes a division by 0 in `ResourceScatterDiv` ([CVE-2021-37642](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37642))\\r\\n* Fixes a heap OOB in `RaggedGather` ([CVE-2021-37641](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37641))\\r\\n* Fixes a `std::abort` raised from `TensorListReserve` ([CVE-2021-37644](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37644))\\r\\n* Fixes a null pointer dereference in `MatrixDiagPartOp` ([CVE-2021-37643](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37643))\\r\\n* Fixes an integer overflow due to conversion to unsigned ([CVE-2021-37645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37645))\\r\\n* Fixes a bad allocation error in `StringNGrams` caused by integer conversion ([CVE-2021-37646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37646))\\r\\n* Fixes a null pointer dereference in `SparseTensorSliceDataset` ([CVE-2021-37647](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37647))\\r\\n* Fixes an incorrect validation of `SaveV2` inputs ([CVE-2021-37648](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37648))\\r\\n* Fixes a null pointer dereference in `UncompressElement` ([CVE-2021-37649](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37649))\\r\\n* Fixes a segfault and a heap buffer overflow in `{Experimental,}DatasetToTFRecord` ([CVE-2021-37650](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37650))\\r\\n* Fixes a heap buffer overflow in `FractionalAvgPoolGrad` ([CVE-2021-37651](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37651))\\r\\n* Fixes a use after free in boosted trees creation ([CVE-2021-37652](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37652))\\r\\n* Fixes a division by 0 in `ResourceGather` ([CVE-2021-37653](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37653))\\r\\n* Fixes a heap OOB and a `CHECK` fail in `ResourceGather` ([CVE-2021-37654](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37654))\\r\\n* Fixes a heap OOB in `ResourceScatterUpdate` ([CVE-2021-37655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37655))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in `RaggedTensorToSparse` ([CVE-2021-37656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37656))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in `MatrixDiagV*` ops ([CVE-2021-37657](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37657))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in `MatrixSetDiagV*` ops ([CVE-2021-37658](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37658))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr and heap OOB in binary cwise ops ([CVE-2021-37659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37659))\\r\\n* Fixes a division by 0 in inplace operations ([CVE-2021-37660](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37660))\\r\\n* Fixes a crash caused by integer conversion to unsigned ([CVE-2021-37661](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37661))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in boosted trees ([CVE-2021-37662](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37662))\\r\\n* Fixes a heap OOB in boosted trees ([CVE-2021-37664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37664))\\r\\n* Fixes vulnerabilities arising from incomplete validation in `QuantizeV2` ([CVE-2021-37663](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37663))\\r\\n* Fixes vulnerabilities arising from incomplete validation in MKL requantization ([CVE-2021-37665](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37665))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in `RaggedTensorToVariant` ([CVE-2021-37666](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37666))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in unicode encoding ([CVE-2021-37667](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37667))\\r\\n* Fixes an FPE in `tf.raw_ops.UnravelIndex` ([CVE-2021-37668](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37668))\\r\\n* Fixes a crash in NMS ops caused by integer conversion to unsigned ([CVE-2021-37669](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37669))\\r\\n* Fixes a heap OOB in `UpperBound` and `LowerBound` ([CVE-2021-37670](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37670))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in map operations ([CVE-2021-37671](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37671))\\r\\n* Fixes a heap OOB in `SdcaOptimizerV2` ([CVE-2021-37672](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37672))\\r\\n* Fixes a `CHECK`-fail in `MapStage` ([CVE-2021-37673](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37673))\\r\\n* Fixes a vulnerability arising from incomplete validation in `MaxPoolGrad` ([CVE-2021-37674](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37674))\\r\\n* Fixes an undefined behavior arising from reference binding to nullptr in shape inference ([CVE-2021-37676](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37676))\\r\\n* Fixes a division by 0 in most convolution operators ([CVE-2021-37675](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37675))\\r\\n* Fixes vulnerabilities arising from missing validation in shape inference for `Dequantize` ([CVE-2021-37677](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37677))\\r\\n* Fixes an arbitrary code execution due to YAML deserialization ([CVE-2021-37678](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37678))\\r\\n* Fixes a heap OOB in nested `tf.map_fn` with `RaggedTensor`s ([CVE-2021-37679](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37679))\\r\\n* Fixes a division by zero in TFLite ([CVE-2021-37680](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37680))\\r\\n* Fixes an NPE in TFLite ([CVE-2021-37681](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37681))\\r\\n* Fixes a vulnerability arising from use of unitialized value in TFLite ([CVE-2021-37682](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37682))\\r\\n* Fixes an FPE in TFLite division operations ([CVE-2021-37683](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37683))\\r\\n* Fixes an FPE in TFLite pooling operations ([CVE-2021-37684](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37684))\\r\\n* Fixes an infinite loop in TFLite ([CVE-2021-37686](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37686))\\r\\n* Fixes a heap OOB in TFLite ([CVE-2021-37685](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37685))\\r\\n* Fixes a heap OOB in TFLite's `Gather*` implementations ([CVE-2021-37687](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37687))\\r\\n* Fixes an undefined behavior arising from null pointer dereference in TFLite ([CVE-2021-37688](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37688))\\r\\n* Fixes an undefined behavior arising from null pointer dereference in TFLite MLIR optimizations ([CVE-2021-37689](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37689))\\r\\n* Fixes a FPE in LSH in TFLite ([CVE-2021-37691](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37691))\\r\\n* Fixes a segfault on strings tensors with mismatched dimensions, arising in Go code ([CVE-2021-37692](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37692))\\r\\n* Fixes a use after free and a potential segfault in shape inference functions ([CVE-2021-37690](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37690))\\r\\n* Updates `curl` to `7.77.0` to handle [CVE-2021-22876](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22876), [CVE-2021-22897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22897), [CVE-2021-22898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22898), and [CVE-2021-22901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22901).\"},\n",
       " {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/83494425',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/83494425/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/83494425/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v2.11.0',\n",
       "  'id': 83494425,\n",
       "  'author': {'login': 'tensorflow-jenkins',\n",
       "   'id': 16359713,\n",
       "   'node_id': 'MDQ6VXNlcjE2MzU5NzEz',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/16359713?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/tensorflow-jenkins',\n",
       "   'html_url': 'https://github.com/tensorflow-jenkins',\n",
       "   'followers_url': 'https://api.github.com/users/tensorflow-jenkins/followers',\n",
       "   'following_url': 'https://api.github.com/users/tensorflow-jenkins/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/tensorflow-jenkins/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/tensorflow-jenkins/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/tensorflow-jenkins/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/tensorflow-jenkins/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/tensorflow-jenkins/repos',\n",
       "   'events_url': 'https://api.github.com/users/tensorflow-jenkins/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/tensorflow-jenkins/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'RE_kwDOArmXAs4E-gYZ',\n",
       "  'tag_name': 'v2.11.0',\n",
       "  'target_commitish': 'r2.11',\n",
       "  'name': 'TensorFlow 2.11.0',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2022-11-16T01:17:12Z',\n",
       "  'updated_at': '2022-11-18T06:01:33Z',\n",
       "  'published_at': '2022-11-18T06:01:33Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v2.11.0',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v2.11.0',\n",
       "  'body': '# Release 2.11.0\\r\\n\\r\\n## Breaking Changes\\r\\n\\r\\n*   The `tf.keras.optimizers.Optimizer` base class now points to the new Keras optimizer, while the old optimizers have been moved to the `tf.keras.optimizers.legacy` namespace.\\r\\n\\r\\n    If you find your workflow failing due to this change, you may be facing one of the following issues:\\r\\n\\r\\n    *   **Checkpoint loading failure.** The new optimizer handles optimizer state differently from the old optimizer, which simplifies the logic of checkpoint saving/loading, but at the cost of breaking checkpoint backward compatibility in some cases. If you want to keep using an old checkpoint, please change your optimizer to `tf.keras.optimizer.legacy.XXX` (e.g. `tf.keras.optimizer.legacy.Adam`).\\r\\n    *   **TF1 compatibility.** The new optimizer, `tf.keras.optimizers.Optimizer`, does not support TF1 any more, so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`. We highly recommend [migrating your workflow to TF2](https://www.tensorflow.org/guide/migrate) for stable support and new features.\\r\\n    *   **Old optimizer API not found.** The new optimizer, `tf.keras.optimizers.Optimizer`, has a different set of public APIs from the old optimizer. These API changes are mostly related to getting rid of slot variables and TF1 support. Please check the API documentation to find alternatives to the missing API. If you must call the deprecated API, please change your optimizer to the legacy optimizer.\\r\\n    *   **Learning rate schedule access.** When using a `tf.keras.optimizers.schedules.LearningRateSchedule`, the new optimizer\\'s `learning_rate` property returns the current learning rate value instead of a `LearningRateSchedule` object as before. If you need to access the `LearningRateSchedule` object, please use `optimizer._learning_rate`.\\r\\n    *   **If you implemented a custom optimizer based on the old optimizer.** Please set your optimizer to subclass `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new optimizer and find it does not support your optimizer, please file an issue in the [Keras GitHub repo](https://github.com/keras-team/keras/issues).\\r\\n    *   **Errors, such as `Cannot recognize variable...`.** The new optimizer requires all optimizer variables to be created at the first `apply_gradients()` or `minimize()` call. If your workflow calls the optimizer to update different parts of the model in multiple stages, please call `optimizer.build(model.trainable_variables)` before the training loop.\\r\\n    *   **Timeout or performance loss.** We don\\'t anticipate this to happen, but if you see such issues, please use the legacy optimizer, and file an issue in the Keras GitHub repo.\\r\\n\\r\\n    The old Keras optimizer will never be deleted, but will not see any new feature additions. New optimizers (for example, `tf.keras.optimizers.Adafactor`) will only be implemented based on the new `tf.keras.optimizers.Optimizer` base class.\\r\\n\\r\\n*   `tensorflow/python/keras` code is a legacy copy of Keras since the TensorFlow v2.7 release, and will be deleted in the v2.12 release. Please remove any import of `tensorflow.python.keras` and use the public API with `from tensorflow import keras` or `import tensorflow as tf; tf.keras`.\\r\\n\\r\\n## Major Features and Improvements\\r\\n\\r\\n*   `tf.lite`:\\r\\n\\r\\n    *   New operations supported: `tf.math.unsorted_segment_sum`, `tf.atan2` and `tf.sign`.\\r\\n    *   Updates to existing operations:\\r\\n          * `tfl.mul` now supports complex32 inputs.\\r\\n\\r\\n*   `tf.experimental.StructuredTensor`:\\r\\n\\r\\n    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible and TensorFlow-native way to encode structured data such as protocol buffers or pandas dataframes.\\r\\n\\r\\n*   `tf.keras`:\\r\\n\\r\\n    *   Added a new `get_metrics_result()` method to `tf.keras.models.Model`.\\r\\n        *   Returns the current metrics values of the model as a dict.\\r\\n    *   Added a new group normalization layer - `tf.keras.layers.GroupNormalization`.\\r\\n    *   Added weight decay support for all Keras optimizers via the `weight_decay` argument.\\r\\n    *   Added the Adafactor optimizer - `tf.keras.optimizers.Adafactor`.\\r\\n    *   Added `warmstart_embedding_matrix` to `tf.keras.utils`.\\r\\n        *   This utility can be used to warmstart an embedding matrix, so you reuse previously-learned word embeddings when working with a new set of words which may include previously unseen words (the embedding vectors for unseen words will be randomly initialized).\\r\\n\\r\\n*   `tf.Variable`:\\r\\n\\r\\n    *   Added `CompositeTensor` as a base class to `ResourceVariable`.\\r\\n        *   This allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\\r\\n    *   Added a new constructor argument `experimental_enable_variable_lifting` to `tf.Variable`, defaulting to `True`.\\r\\n        *   When it\\'s set to `False`, the variable won\\'t be lifted out of `tf.function`; thus it can be used as a `tf.function`-local variable: during each execution of the `tf.function`, the variable will be created and then disposed, similar to a local (that is, stack-allocated) variable in C/C++. Currently, `experimental_enable_variable_lifting=False` only works on non-XLA devices (for example, under `@tf.function(jit_compile=False)`).\\r\\n\\r\\n*   TF SavedModel:\\r\\n\\r\\n    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb` file is a protobuf containing the \"fingerprint\" of the SavedModel. See the [RFC](https://github.com/tensorflow/community/pull/415) for more details regarding its design and properties.\\r\\n        \\r\\n*   TF pip:\\r\\n\\r\\n    *   Windows CPU-builds for x86/x64 processors are now built, maintained, tested and released by a third party: Intel. Installing the Windows-native pip packages for `tensorflow` or `tensorflow-cpu` would install Intel\\'s `tensorflow-intel` package. These packages are provided on an as-is basis. TensorFlow will use reasonable efforts to maintain the availability and integrity of this pip package. There may be delays if the third party fails to release the pip package. For using TensorFlow GPU on Windows, you will need to install TensorFlow in WSL2.\\r\\n\\r\\n## Bug Fixes and Other Changes\\r\\n\\r\\n*   `tf.image`:\\r\\n\\r\\n    *   Added an optional parameter `return_index_map` to `tf.image.ssim`, which causes the returned value to be the local SSIM map instead of the global mean.\\r\\n\\r\\n*   TF Core:\\r\\n\\r\\n    *   `tf.custom_gradient` can now be applied to functions that accept \"composite\" tensors, such as `tf.RaggedTensor`, as inputs.\\r\\n    *   Fix device placement issues related to datasets with ragged tensors of strings (i.e. variant encoded data with types not supported on GPU).\\r\\n    *   `experimental_follow_type_hints` for `tf.function` has been deprecated. Please `use input_signature` or `reduce_retracing` to minimize retracing.\\r\\n\\r\\n*   `tf.SparseTensor`:\\r\\n\\r\\n    *   Introduced `set_shape`, which sets the static dense shape of the sparse tensor and has the same semantics as `tf.Tensor.set_shape`.\\r\\n\\r\\n## Security\\r\\n\\r\\n* TF is currently using giflib 5.2.1 which has [CVE-2022-28506](https://nvd.nist.gov/vuln/detail/CVE-2022-28506). TF is not affected by the CVE as it does not use `DumpScreen2RGB` at all.\\r\\n*   Fixes an OOB seg fault in `DynamicStitch` due to missing validation ([CVE-2022-41883](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41883))\\r\\n*   Fixes an overflow in `tf.keras.losses.poisson` ([CVE-2022-41887](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41887))\\r\\n*   Fixes a heap OOB failure in `ThreadUnsafeUnigramCandidateSampler` caused by missing validation ([CVE-2022-41880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41880))\\r\\n*   Fixes a segfault in `ndarray_tensor_bridge` ([CVE-2022-41884](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41884))\\r\\n*   Fixes an overflow in `FusedResizeAndPadConv2D` ([CVE-2022-41885](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41885))\\r\\n*   Fixes a overflow in `ImageProjectiveTransformV2` ([CVE-2022-41886](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41886))\\r\\n*   Fixes an FPE in `tf.image.generate_bounding_box_proposals` on GPU ([CVE-2022-41888](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41888))\\r\\n*   Fixes a segfault in `pywrap_tfe_src` caused by invalid attributes ([CVE-2022-41889](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41889))\\r\\n*   Fixes a `CHECK` fail in `BCast` ([CVE-2022-41890](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41890))\\r\\n*   Fixes a segfault in `TensorListConcat` ([CVE-2022-41891](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41891))\\r\\n*   Fixes a `CHECK_EQ` fail in `TensorListResize` ([CVE-2022-41893](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41893))\\r\\n*   Fixes an overflow in `CONV_3D_TRANSPOSE` on TFLite ([CVE-2022-41894](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41894))\\r\\n*   Fixes a heap OOB in `MirrorPadGrad` ([CVE-2022-41895](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41895))\\r\\n*   Fixes a crash in `Mfcc` ([CVE-2022-41896](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41896))\\r\\n*   Fixes a heap OOB in `FractionalMaxPoolGrad` ([CVE-2022-41897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41897))\\r\\n*   Fixes a `CHECK` fail in `SparseFillEmptyRowsGrad` ([CVE-2022-41898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41898))\\r\\n*   Fixes a `CHECK` fail in `SdcaOptimizer` ([CVE-2022-41899](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41899))\\r\\n*   Fixes a heap OOB in `FractionalAvgPool` and `FractionalMaxPool`([CVE-2022-41900](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41900))\\r\\n*   Fixes a `CHECK_EQ` in `SparseMatrixNNZ` ([CVE-2022-41901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41901))\\r\\n*   Fixes an OOB write in grappler ([CVE-2022-41902](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41902))\\r\\n*   Fixes a overflow in `ResizeNearestNeighborGrad` ([CVE-2022-41907](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41907))\\r\\n*   Fixes a `CHECK` fail in `PyFunc` ([CVE-2022-41908](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41908))\\r\\n*   Fixes a segfault in `CompositeTensorVariantToComponents` ([CVE-2022-41909](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41909))\\r\\n*   Fixes a invalid char to bool conversion in printing a tensor ([CVE-2022-41911](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41911))\\r\\n*   Fixes a heap overflow in `QuantizeAndDequantizeV2` ([CVE-2022-41910](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41910))\\r\\n*   Fixes a `CHECK` failure in `SobolSample` via missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\\r\\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` in eager mode ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\\r\\n\\r\\n## Thanks to our Contributors\\r\\n\\r\\nThis release contains contributions from many people at Google, as well as:\\r\\n\\r\\n103yiran, 8bitmp3, Aakar Dwivedi, Alexander Grund, alif_elham, Aman Agarwal, amoitra, Andrei Ivanov, andreii, Andrew Goodbody, angerson, Ashay Rane, Azeem Shaikh, Ben Barsdell, bhack, Bhavani Subramanian, Cedric Nugteren, Chandra Kumar Ramasamy, Christopher Bate, CohenAriel, Cotarou, cramasam, Enrico Minack, Francisco Unda, Frederic Bastien, gadagashwini, Gauri1 Deshpande, george, Jake, Jeff, Jerry Ge, Jingxuan He, Jojimon Varghese, Jonathan Dekhtiar, Kaixi Hou, Kanvi Khanna, kcoul, Keith Smiley, Kevin Hu, Kun Lu, kushanam, Lianmin Zheng, liuyuanqiang, Louis Sugy, Mahmoud Abuzaina, Marius Brehler, mdfaijul, Meenakshi Venkataraman, Milos Puzovic, mohantym, Namrata-Ibm, Nathan John Sircombe, Nathan Luehr, Olaf Lipinski, Om Thakkar, Osman F Bayram, Patrice Vignola, Pavani Majety, Philipp Hack, Prianka Liz Kariat, Rahul Batra, RajeshT, Renato Golin, riestere, Roger Iyengar, Rohit Santhanam, Rsanthanam-Amd, Sadeed Pv, Samuel Marks, Shimokawa, Naoaki, Siddhesh Kothadi, Simengliu-Nv, Sindre Seppola, snadampal, Srinivasan Narayanamoorthy, sushreebarsa, syedshahbaaz, Tamas Bela Feher, Tatwai Chong, Thibaut Goetghebuer-Planchon, tilakrayal, Tom Anderson, Tomohiro Endo, Trevor Morris, vibhutisawant, Victor Zhang, Vremold, Xavier Bonaventura, Yanming Wang, Yasir Modak, Yimei Sun, Yong Tang, Yulv-Git, zhuoran.liu, zotanika',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/83494425/reactions',\n",
       "   'total_count': 100,\n",
       "   '+1': 50,\n",
       "   '-1': 0,\n",
       "   'laugh': 3,\n",
       "   'hooray': 15,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 28,\n",
       "   'eyes': 4}},\n",
       " {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/145540492',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/145540492/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/145540492/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v2.15.1',\n",
       "  'id': 145540492,\n",
       "  'author': {'login': 'tensorflow-jenkins',\n",
       "   'id': 16359713,\n",
       "   'node_id': 'MDQ6VXNlcjE2MzU5NzEz',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/16359713?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/tensorflow-jenkins',\n",
       "   'html_url': 'https://github.com/tensorflow-jenkins',\n",
       "   'followers_url': 'https://api.github.com/users/tensorflow-jenkins/followers',\n",
       "   'following_url': 'https://api.github.com/users/tensorflow-jenkins/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/tensorflow-jenkins/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/tensorflow-jenkins/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/tensorflow-jenkins/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/tensorflow-jenkins/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/tensorflow-jenkins/repos',\n",
       "   'events_url': 'https://api.github.com/users/tensorflow-jenkins/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/tensorflow-jenkins/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'RE_kwDOArmXAs4IrMWM',\n",
       "  'tag_name': 'v2.15.1',\n",
       "  'target_commitish': 'r2.15',\n",
       "  'name': 'TensorFlow 2.15.1',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2024-03-08T02:19:10Z',\n",
       "  'updated_at': '2024-03-08T19:09:29Z',\n",
       "  'published_at': '2024-03-08T19:09:29Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v2.15.1',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v2.15.1',\n",
       "  'body': '# Release 2.15.1\\r\\n\\r\\n### Bug Fixes and Other Changes\\r\\n\\r\\n*   `ml_dtypes` runtime dependency is updated to `0.3.1` to fix package conflict issues',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/145540492/reactions',\n",
       "   'total_count': 59,\n",
       "   '+1': 29,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 8,\n",
       "   'confused': 0,\n",
       "   'heart': 9,\n",
       "   'rocket': 9,\n",
       "   'eyes': 4}},\n",
       " {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/239760792',\n",
       "  'assets_url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/239760792/assets',\n",
       "  'upload_url': 'https://uploads.github.com/repos/tensorflow/tensorflow/releases/239760792/assets{?name,label}',\n",
       "  'html_url': 'https://github.com/tensorflow/tensorflow/releases/tag/v2.20.0',\n",
       "  'id': 239760792,\n",
       "  'author': {'login': 'tensorflow-jenkins',\n",
       "   'id': 16359713,\n",
       "   'node_id': 'MDQ6VXNlcjE2MzU5NzEz',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/16359713?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/tensorflow-jenkins',\n",
       "   'html_url': 'https://github.com/tensorflow-jenkins',\n",
       "   'followers_url': 'https://api.github.com/users/tensorflow-jenkins/followers',\n",
       "   'following_url': 'https://api.github.com/users/tensorflow-jenkins/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/tensorflow-jenkins/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/tensorflow-jenkins/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/tensorflow-jenkins/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/tensorflow-jenkins/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/tensorflow-jenkins/repos',\n",
       "   'events_url': 'https://api.github.com/users/tensorflow-jenkins/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/tensorflow-jenkins/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'node_id': 'RE_kwDOArmXAs4OSnWY',\n",
       "  'tag_name': 'v2.20.0',\n",
       "  'target_commitish': 'r2.20',\n",
       "  'name': 'TensorFlow 2.20.0',\n",
       "  'draft': False,\n",
       "  'immutable': False,\n",
       "  'prerelease': False,\n",
       "  'created_at': '2025-08-07T05:16:45Z',\n",
       "  'updated_at': '2025-08-13T17:45:14Z',\n",
       "  'published_at': '2025-08-13T17:45:14Z',\n",
       "  'assets': [],\n",
       "  'tarball_url': 'https://api.github.com/repos/tensorflow/tensorflow/tarball/v2.20.0',\n",
       "  'zipball_url': 'https://api.github.com/repos/tensorflow/tensorflow/zipball/v2.20.0',\n",
       "  'body': '# Release 2.20.0\\r\\n\\r\\n## TensorFlow\\r\\n\\r\\n### Breaking Changes\\r\\n\\r\\n* The `tensorflow-io-gcs-filesystem` package is now optional, due its uncertain, and limited support. To install it alongside `tensorflow`, run `pip install \"tensorflow[gcs-filesystem]\"`.\\r\\n\\r\\n### Major Features and Improvements\\r\\n\\r\\n* `tf.data`\\r\\n    * Adds `autotune.min_parallelism` to `tf.data.Options` to enable faster input pipeline warm up.\\r\\n* `tf.lite`\\r\\n    * tf.lite will be deprecated, in favor of the new repo https://github.com/google-ai-edge/LiteRT.\\r\\n    * The duplicated source will also be removed from the TF repo.\\r\\n\\r\\n## Thanks to our Contributors\\r\\n\\r\\nThis release contains contributions from many people at Google, as well as:\\r\\n\\r\\n1ndig0, 372046933, abhinav, afzpatel, Akhil Goel, Alain Carlucci, Aleksei, Alen Huang, Alex, Amrinfathima-Mcw, Aravindh Balaji, Armand Picard, Aseem Athale, Ashiq Imran, Assoap, Chao, Chase Riley Roberts, Chenhao Jiang, chunhsue, chuntl, Chunyu Jin, Corentin Kerisit, Crefeda Rodrigues, dependabot[bot], Dragan Mladjenovic, Elen Kalda, Felix Thomasmathibalan, gabeweisz, Gauri Deshpande, Georg Stefan Schmid, Guozhong Zhuang, Harsha H S, Harshith_N, Hugo Mano, Ian Tayler Lessa, Jack Wolfard, James Ward, Jane Liu, Jaroslav Sevcik, JD, Jerry-Ge, Jian Li, Jinzhe Zeng, jiunkaiy, Johannes Reifferscheid, johnnkp, junweifu, Kanvi Khanna, Kasper Nielsen, Linzb-Xyz, Luke Hutton, Mahmoud Abuzaina, Mathew Odden, Michael Platings, misterBart, Mitchell Ludwig, Mmakevic-Amd, mraunak, NamanAgarwal0905, Namrata-Ibm, Neuropilot-Captain, nhatle, Nicholas Wilson, Nikhil Shinde, Olli Lupton, Patrick J. Lopresti, Pavel Emeliyanenko, Pearu Peterson, pemeliya, Peng Sun, Philipp Hack, Pratham-Mcw, RahulSudarMCW, RakshithGB, Rakshithgb-Fujitsu, RuslanSemchenko, Ruturaj Vaidya, Sachin Muradi, sandeepgupta12, SaoirseARM, Sergey Kozub, Sevin Fide Varoglu, Shanbin Ke, Shaogang Wang, Shraiysh Vaishay, Siddhartha Menon, spiao, Swatheesh Muralidharan, Tai Ly, Terry Sun, Thibaut Goetghebuer-Planchon, Thomas Dickerson, Tilak, Tj Xu, Trevor Morris, tyb0807, vfdev, Wei Wang, wokron, wondertx, Xuefei Jiang, Yaowei Zhou, Zentrik, Ziyun Cheng, Zoranjovanovic-Ns',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/tensorflow/tensorflow/releases/239760792/reactions',\n",
       "   'total_count': 13,\n",
       "   '+1': 13,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0}}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_spaced_releases_summary(owner, repo_name, num_releases=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a82d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repository_at_commit(owner, repo_name, commit_sha):\n",
    "    \"\"\"\n",
    "    R√©cup√®re les informations d'un repository √† un commit sp√©cifique\n",
    "    \n",
    "    Args:\n",
    "        owner (str): Propri√©taire du repository\n",
    "        repo_name (str): Nom du repository\n",
    "        commit_sha (str): SHA du commit\n",
    "    \n",
    "    Returns:\n",
    "        dict: Informations du repository √† ce commit\n",
    "    \"\"\"\n",
    "    url = f\"{GITHUB_API_URL}/repos/{owner}/{repo_name}/git/trees/{commit_sha}\"\n",
    "    params = {\"recursive\": \"1\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la r√©cup√©ration du tree pour {commit_sha}: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a118136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_languages_github_style(tree_data):\n",
    "    \"\"\"\n",
    "    Analyse les langages en se rapprochant de la m√©thode GitHub\n",
    "    \"\"\"\n",
    "    language_extensions = {\n",
    "        '.py': 'Python', '.js': 'JavaScript', '.ts': 'TypeScript',\n",
    "        '.java': 'Java', '.cpp': 'C++', '.c': 'C', '.cs': 'C#',\n",
    "        '.php': 'PHP', '.rb': 'Ruby', '.go': 'Go', '.rs': 'Rust',\n",
    "        '.kt': 'Kotlin', '.swift': 'Swift', '.scala': 'Scala',\n",
    "        '.r': 'R', '.sql': 'SQL', '.html': 'HTML', '.css': 'CSS',\n",
    "        '.scss': 'SCSS', '.vue': 'Vue', '.jsx': 'JSX', '.tsx': 'TSX'\n",
    "    }\n",
    "    \n",
    "    # Dossiers √† ignorer (comme GitHub)\n",
    "    ignored_paths = ['/vendor/', '/node_modules/', '/build/', '/dist/', \n",
    "                    '/.git/', '/docs/', '/documentation/', '/test/', '/tests/']\n",
    "    \n",
    "    language_data = {}\n",
    "    \n",
    "    if 'tree' in tree_data:\n",
    "        for file_info in tree_data['tree']:\n",
    "            if file_info['type'] == 'blob':\n",
    "                path = file_info['path']\n",
    "                \n",
    "                # Ignorer certains dossiers\n",
    "                if any(ignored in path.lower() for ignored in ignored_paths):\n",
    "                    continue\n",
    "                \n",
    "                # Ignorer les fichiers README, LICENSE, etc.\n",
    "                filename = path.split('/')[-1].lower()\n",
    "                if filename.startswith(('readme', 'license', 'changelog')):\n",
    "                    continue\n",
    "                \n",
    "                # Analyser l'extension\n",
    "                for ext, lang in language_extensions.items():\n",
    "                    if path.lower().endswith(ext):\n",
    "                        if lang not in language_data:\n",
    "                            language_data[lang] = {'files': 0, 'size': 0}\n",
    "                        \n",
    "                        language_data[lang]['files'] += 1\n",
    "                        # Approximation de taille (GitHub utilise les octets r√©els)\n",
    "                        language_data[lang]['size'] += file_info.get('size', 1000)\n",
    "                        break\n",
    "    \n",
    "    return language_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46aece01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_release_languages_historical(owner, repo_name, release):\n",
    "    \"\"\"\n",
    "    Analyse les langages utilis√©s dans une release sp√©cifique en utilisant l'historique Git\n",
    "    \n",
    "    Args:\n",
    "        owner (str): Propri√©taire du repository\n",
    "        repo_name (str): Nom du repository\n",
    "        release (dict): Donn√©es de la release\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analyse des langages avec pourcentages bas√©e sur les octets de la release\n",
    "    \"\"\"\n",
    "    tag = release['tag_name']\n",
    "    date = (release['published_at'] or release['created_at'])[:10]\n",
    "    \n",
    "    print(f\"\\nüîç ANALYSE HISTORIQUE DES LANGAGES - {tag} ({date})\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # R√©cup√©rer le commit SHA de la release\n",
    "    commit_sha = release.get('target_commitish', 'main')\n",
    "    if not commit_sha:\n",
    "        # Essayer de r√©cup√©rer le SHA depuis l'API des tags\n",
    "        url = f\"{GITHUB_API_URL}/repos/{owner}/{repo_name}/git/refs/tags/{tag}\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            tag_data = response.json()\n",
    "            commit_sha = tag_data['object']['sha']\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erreur lors de la r√©cup√©ration du SHA pour {tag}: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    # R√©cup√©rer l'arbre des fichiers pour ce commit\n",
    "    tree_data = get_repository_at_commit(owner, repo_name, commit_sha)\n",
    "    \n",
    "    if not tree_data:\n",
    "        print(f\"Impossible de r√©cup√©rer l'arbre pour {tag}\")\n",
    "        return {}\n",
    "    \n",
    "    # Analyser les langages avec taille des fichiers\n",
    "    language_data = analyze_languages_github_style(tree_data)\n",
    "\n",
    "    if not language_data:\n",
    "        print(\"Aucun langage d√©tect√© dans cette release\")\n",
    "        return {}\n",
    "\n",
    "    # Extraire les donn√©es (fichiers et taille)\n",
    "    language_stats = {}\n",
    "    total_bytes = 0\n",
    "    \n",
    "    for lang, data in language_data.items():\n",
    "        language_stats[lang] = {\n",
    "            'files': data['files'],\n",
    "            'bytes': data['size']\n",
    "        }\n",
    "        total_bytes += data['size']\n",
    "    \n",
    "    # Calculer les pourcentages bas√©s sur les octets\n",
    "    languages_analysis = {}\n",
    "    for lang, stats in language_stats.items():\n",
    "        percentage = (stats['bytes'] / total_bytes) * 100 if total_bytes > 0 else 0\n",
    "        languages_analysis[lang] = {\n",
    "            'files': stats['files'],\n",
    "            'bytes': stats['bytes'],\n",
    "            'percentage': percentage\n",
    "        }\n",
    "    \n",
    "    # Trier par pourcentage d√©croissant\n",
    "    sorted_languages = sorted(languages_analysis.items(), \n",
    "                             key=lambda x: x[1]['percentage'], \n",
    "                             reverse=True)\n",
    "    \n",
    "    print(\"üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Total d'octets analys√©s: {total_bytes:,}\")\n",
    "    print(f\"Total de fichiers analys√©s: {sum(lang['files'] for lang in languages_analysis.values())}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for lang, stats in sorted_languages:\n",
    "        bar_length = int(stats['percentage'] / 2)  # Barre de 50 chars max\n",
    "        bar = \"‚ñà\" * bar_length + \"‚ñë\" * (50 - bar_length)\n",
    "        print(f\"{lang:<12} {stats['percentage']:6.1f}% |{bar}| ({stats['bytes']:,} octets, {stats['files']} fichiers)\")\n",
    "    \n",
    "    return languages_analysis\n",
    "\n",
    "\n",
    "def analyze_all_releases_languages_historical(owner, repo_name, releases):\n",
    "    \"\"\"\n",
    "    Analyse les langages pour toutes les releases s√©lectionn√©es avec donn√©es historiques\n",
    "    \n",
    "    Args:\n",
    "        owner (str): Propri√©taire du repository\n",
    "        repo_name (str): Nom du repository\n",
    "        releases (list): Liste des releases √† analyser\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analyse compl√®te des langages par release avec donn√©es historiques\n",
    "    \"\"\"\n",
    "    print(f\"\\nüåê ANALYSE HISTORIQUE DES LANGAGES POUR TOUTES LES RELEASES\")\n",
    "    print(f\"Repository: {owner}/{repo_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    all_analyses = {}\n",
    "    \n",
    "    for i, release in enumerate(releases, 1):\n",
    "        tag = release['tag_name']\n",
    "        date = (release['published_at'] or release['created_at'])[:10]\n",
    "        name = release['name'] or tag\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(releases)}] Release: {name} ({tag}) - {date}\")\n",
    "        \n",
    "        # Analyser les langages historiques pour cette release\n",
    "        languages_analysis = analyze_release_languages_historical(owner, repo_name, release)\n",
    "        all_analyses[tag] = {\n",
    "            'release_info': release,\n",
    "            'languages': languages_analysis\n",
    "        }\n",
    "    \n",
    "    return all_analyses\n",
    "def get_languages_evolution_summary_historical(languages_analyses):\n",
    "    \"\"\"\n",
    "    R√©sume l'√©volution des langages √† travers les releases (version historique bas√©e sur octets)\n",
    "    \n",
    "    Args:\n",
    "        languages_analyses (dict): Analyses des langages par release\n",
    "    \n",
    "    Returns:\n",
    "        dict: R√©sum√© de l'√©volution avec donn√©es historiques\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìà R√âSUM√â DE L'√âVOLUTION HISTORIQUE DES LANGAGES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Collecter tous les langages uniques\n",
    "    all_languages = set()\n",
    "    for analysis in languages_analyses.values():\n",
    "        if analysis['languages']:\n",
    "            all_languages.update(analysis['languages'].keys())\n",
    "    \n",
    "    if not all_languages:\n",
    "        print(\"Aucun langage d√©tect√© dans les releases analys√©es\")\n",
    "        return {}\n",
    "    \n",
    "    # Analyser la pr√©sence de chaque langage\n",
    "    language_presence = {}\n",
    "    for lang in all_languages:\n",
    "        appearances = 0\n",
    "        total_percentage = 0\n",
    "        total_files = 0\n",
    "        total_bytes = 0\n",
    "        \n",
    "        for analysis in languages_analyses.values():\n",
    "            if analysis['languages'] and lang in analysis['languages']:\n",
    "                appearances += 1\n",
    "                total_percentage += analysis['languages'][lang]['percentage']\n",
    "                total_files += analysis['languages'][lang]['files']\n",
    "                total_bytes += analysis['languages'][lang]['bytes']\n",
    "        \n",
    "        language_presence[lang] = {\n",
    "            'appearances': appearances,\n",
    "            'avg_percentage': total_percentage / appearances if appearances > 0 else 0,\n",
    "            'total_files': total_files,\n",
    "            'total_bytes': total_bytes,\n",
    "            'total_releases': len(languages_analyses)\n",
    "        }\n",
    "    \n",
    "    # Trier par pourcentage moyen\n",
    "    sorted_langs = sorted(language_presence.items(), \n",
    "                         key=lambda x: x[1]['avg_percentage'], \n",
    "                         reverse=True)\n",
    "    \n",
    "    print(\"üèÜ LANGAGES LES PLUS UTILIS√âS (moyenne sur toutes les releases - bas√© sur octets):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Langage':<12} {'Moy %':<8} {'Pr√©sence':<10} {'Total octets':<15} {'Total fichiers':<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for lang, stats in sorted_langs[:10]:  # Top 10\n",
    "        presence_rate = (stats['appearances'] / stats['total_releases']) * 100\n",
    "        print(f\"{lang:<12} {stats['avg_percentage']:6.1f}% {presence_rate:7.0f}% {stats['total_bytes']:12,} {stats['total_files']:12d}\")\n",
    "    \n",
    "    return language_presence\n",
    "\n",
    "def get_complete_releases_analysis_historical(owner, repo_name, num_releases=8):\n",
    "    \"\"\"\n",
    "    Analyse compl√®te des releases avec langages historiques\n",
    "    \n",
    "    Args:\n",
    "        owner (str): Propri√©taire du repository\n",
    "        repo_name (str): Nom du repository\n",
    "        num_releases (int): Nombre de releases √† analyser\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (releases_s√©lectionn√©es, analyse_langages_historique)\n",
    "    \"\"\"\n",
    "    # R√©cup√©rer les releases avec espacement temporel\n",
    "    selected_releases = get_time_spaced_releases_summary(owner, repo_name, num_releases)\n",
    "    \n",
    "    if not selected_releases:\n",
    "        return [], {}\n",
    "    \n",
    "    # Analyser les langages historiques\n",
    "    languages_analysis = analyze_all_releases_languages_historical(owner, repo_name, selected_releases)\n",
    "    \n",
    "    # R√©sum√© de l'√©volution\n",
    "    evolution_summary = get_languages_evolution_summary_historical(languages_analysis)\n",
    "    \n",
    "    return selected_releases, languages_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ce02576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ S√âLECTION DE 8 RELEASES AVEC ESPACEMENT TEMPOREL MAXIMAL\n",
      "Repository: tensorflow/tensorflow\n",
      "================================================================================\n",
      "R√©cup√©ration de toutes les releases pour tensorflow/tensorflow...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Page 1: 100 releases (Total: 100)\n",
      "  Page 2: 100 releases (Total: 200)\n",
      "  Page 3: 19 releases (Total: 219)\n",
      "Total r√©cup√©r√©: 219 releases\n",
      "P√©riode: 2016-02-16 ‚Üí 2025-08-13\n",
      "\n",
      "Premi√®res releases:\n",
      "  1. 2025-08-13: TensorFlow 2.19.1\n",
      "  2. 2025-08-13: TensorFlow 2.20.0\n",
      "  3. 2025-07-28: TensorFlow 2.20.0-rc0\n",
      "  4. 2025-03-11: TensorFlow 2.18.1\n",
      "  5. 2025-03-12: TensorFlow 2.19.0\n",
      "  ...\n",
      "Releases totales: 219\n",
      "Releases stables (sans pre-releases/drafts): 108\n",
      "P√©riode totale: 3465 jours\n",
      "Intervalle cible: 495.0 jours\n",
      "\n",
      "üìã RELEASES S√âLECTIONN√âES (du plus ancien au plus r√©cent):\n",
      "--------------------------------------------------------------------------------\n",
      " 1. 2016-02-16 - TensorFlow 0.6.0 (v0.6.0)\n",
      " 2. 2017-06-30 - TensorFlow 1.2.1 (v1.2.1)\n",
      " 3. 2018-11-05 - TensorFlow 1.12.0 (v1.12.0)\n",
      " 4. 2020-01-26 - TensorFlow 1.15.2 (v1.15.2)\n",
      " 5. 2021-08-10 - TensorFlow 2.5.1 (v2.5.1)\n",
      " 6. 2022-11-18 - TensorFlow 2.11.0 (v2.11.0)\n",
      " 7. 2024-03-08 - TensorFlow 2.15.1 (v2.15.1)\n",
      " 8. 2025-08-13 - TensorFlow 2.20.0 (v2.20.0)\n",
      "\n",
      "üìä INTERVALLES TEMPORELS R√âALIS√âS:\n",
      "--------------------------------------------------\n",
      "  2016-02-16 ‚Üí 2017-06-30:  499 jours ( 16.4 mois)\n",
      "  2017-06-30 ‚Üí 2018-11-05:  493 jours ( 16.2 mois)\n",
      "  2018-11-05 ‚Üí 2020-01-26:  446 jours ( 14.7 mois)\n",
      "  2020-01-26 ‚Üí 2021-08-10:  562 jours ( 18.5 mois)\n",
      "  2021-08-10 ‚Üí 2022-11-18:  464 jours ( 15.2 mois)\n",
      "  2022-11-18 ‚Üí 2024-03-08:  476 jours ( 15.6 mois)\n",
      "  2024-03-08 ‚Üí 2025-08-13:  522 jours ( 17.1 mois)\n",
      "\n",
      "Statistiques des intervalles:\n",
      "  Moyenne:    495 jours ( 16.2 mois)\n",
      "  Minimum:    446 jours ( 14.7 mois)\n",
      "  Maximum:    562 jours ( 18.5 mois)\n",
      "\n",
      "P√©riode totale couverte: 3465 jours (9.5 ann√©es)\n",
      "\n",
      "üåê ANALYSE HISTORIQUE DES LANGAGES POUR TOUTES LES RELEASES\n",
      "Repository: tensorflow/tensorflow\n",
      "================================================================================\n",
      "\n",
      "[1/8] Release: TensorFlow 0.6.0 (v0.6.0) - 2016-02-16\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v0.6.0 (2016-02-16)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 54,221,259\n",
      "Total de fichiers analys√©s: 3267\n",
      "------------------------------------------------------------\n",
      "Python         79.9% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (43,334,096 octets, 2821 fichiers)\n",
      "HTML           14.1% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (7,669,580 octets, 235 fichiers)\n",
      "Go              4.0% |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,175,693 octets, 41 fichiers)\n",
      "Java            1.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (668,277 octets, 110 fichiers)\n",
      "C++             0.4% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (216,181 octets, 15 fichiers)\n",
      "C               0.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (86,416 octets, 29 fichiers)\n",
      "Swift           0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (51,813 octets, 11 fichiers)\n",
      "C#              0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (13,585 octets, 2 fichiers)\n",
      "JavaScript      0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,857 octets, 1 fichiers)\n",
      "CSS             0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,761 octets, 2 fichiers)\n",
      "\n",
      "[2/8] Release: TensorFlow 1.2.1 (v1.2.1) - 2017-06-30\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v1.2.1 (2017-06-30)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 23,288,507\n",
      "Total de fichiers analys√©s: 2060\n",
      "------------------------------------------------------------\n",
      "Python         83.8% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (19,510,740 octets, 1627 fichiers)\n",
      "TypeScript      6.2% |‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (1,452,586 octets, 150 fichiers)\n",
      "HTML            4.9% |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (1,141,574 octets, 201 fichiers)\n",
      "Go              3.6% |‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (845,445 octets, 28 fichiers)\n",
      "Java            1.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (287,825 octets, 38 fichiers)\n",
      "C               0.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (35,558 octets, 8 fichiers)\n",
      "JavaScript      0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (14,005 octets, 7 fichiers)\n",
      "CSS             0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (774 octets, 1 fichiers)\n",
      "\n",
      "[3/8] Release: TensorFlow 1.12.0 (v1.12.0) - 2018-11-05\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v1.12.0 (2018-11-05)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 44,428,032\n",
      "Total de fichiers analys√©s: 2979\n",
      "------------------------------------------------------------\n",
      "Python         84.8% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (37,672,605 octets, 2831 fichiers)\n",
      "HTML           10.5% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (4,680,032 octets, 1 fichiers)\n",
      "Go              2.8% |‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (1,253,646 octets, 32 fichiers)\n",
      "Java            1.7% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (767,827 octets, 104 fichiers)\n",
      "C               0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (45,476 octets, 9 fichiers)\n",
      "C#              0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (8,446 octets, 2 fichiers)\n",
      "\n",
      "[4/8] Release: TensorFlow 1.15.2 (v1.15.2) - 2020-01-26\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v1.15.2 (2020-01-26)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 55,390,943\n",
      "Total de fichiers analys√©s: 3714\n",
      "------------------------------------------------------------\n",
      "Python         82.3% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (45,564,653 octets, 3348 fichiers)\n",
      "HTML            8.4% |‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (4,680,032 octets, 1 fichiers)\n",
      "C++             4.7% |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,584,951 octets, 179 fichiers)\n",
      "Go              3.0% |‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (1,670,128 octets, 38 fichiers)\n",
      "Java            1.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (679,372 octets, 95 fichiers)\n",
      "C               0.3% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (165,631 octets, 39 fichiers)\n",
      "Swift           0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (37,614 octets, 12 fichiers)\n",
      "C#              0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (8,562 octets, 2 fichiers)\n",
      "\n",
      "[5/8] Release: TensorFlow 2.5.1 (v2.5.1) - 2021-08-10\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v2.5.1 (2021-08-10)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 49,426,635\n",
      "Total de fichiers analys√©s: 2862\n",
      "------------------------------------------------------------\n",
      "Python         85.0% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (42,017,663 octets, 2695 fichiers)\n",
      "HTML            9.5% |‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (4,693,402 octets, 3 fichiers)\n",
      "Go              4.1% |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,008,827 octets, 42 fichiers)\n",
      "Java            1.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (509,975 octets, 74 fichiers)\n",
      "C               0.3% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (147,902 octets, 36 fichiers)\n",
      "Swift           0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (33,870 octets, 9 fichiers)\n",
      "C#              0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (13,395 octets, 2 fichiers)\n",
      "C++             0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (1,601 octets, 1 fichiers)\n",
      "\n",
      "[6/8] Release: TensorFlow 2.11.0 (v2.11.0) - 2022-11-18\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v2.11.0 (2022-11-18)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 48,253,104\n",
      "Total de fichiers analys√©s: 2808\n",
      "------------------------------------------------------------\n",
      "Python         84.4% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (40,738,880 octets, 2633 fichiers)\n",
      "HTML            9.7% |‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (4,693,402 octets, 3 fichiers)\n",
      "Go              4.3% |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,095,489 octets, 41 fichiers)\n",
      "Java            1.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (577,346 octets, 90 fichiers)\n",
      "C               0.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (85,059 octets, 28 fichiers)\n",
      "Swift           0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (49,432 octets, 11 fichiers)\n",
      "C#              0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (13,496 octets, 2 fichiers)\n",
      "\n",
      "[7/8] Release: TensorFlow 2.15.1 (v2.15.1) - 2024-03-08\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v2.15.1 (2024-03-08)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 50,514,005\n",
      "Total de fichiers analys√©s: 2992\n",
      "------------------------------------------------------------\n",
      "Python         84.8% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (42,812,632 octets, 2795 fichiers)\n",
      "HTML            9.3% |‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (4,693,402 octets, 3 fichiers)\n",
      "Go              4.3% |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,178,680 octets, 41 fichiers)\n",
      "Java            1.3% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (667,210 octets, 110 fichiers)\n",
      "C               0.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (92,023 octets, 29 fichiers)\n",
      "Swift           0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (51,674 octets, 11 fichiers)\n",
      "C#              0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (13,584 octets, 2 fichiers)\n",
      "JavaScript      0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (4,800 octets, 1 fichiers)\n",
      "\n",
      "[8/8] Release: TensorFlow 2.20.0 (v2.20.0) - 2025-08-13\n",
      "\n",
      "üîç ANALYSE HISTORIQUE DES LANGAGES - v2.20.0 (2025-08-13)\n",
      "============================================================\n",
      "üìä R√âPARTITION DES LANGAGES (bas√©e sur les octets de code):\n",
      "------------------------------------------------------------\n",
      "Total d'octets analys√©s: 54,076,672\n",
      "Total de fichiers analys√©s: 3253\n",
      "------------------------------------------------------------\n",
      "Python         79.9% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (43,207,811 octets, 2808 fichiers)\n",
      "HTML           14.2% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (7,669,580 octets, 235 fichiers)\n",
      "Go              4.0% |‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,173,960 octets, 41 fichiers)\n",
      "Java            1.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (668,277 octets, 110 fichiers)\n",
      "C++             0.4% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (199,612 octets, 14 fichiers)\n",
      "C               0.2% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (86,416 octets, 29 fichiers)\n",
      "Swift           0.1% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (51,813 octets, 11 fichiers)\n",
      "C#              0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (13,585 octets, 2 fichiers)\n",
      "JavaScript      0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,857 octets, 1 fichiers)\n",
      "CSS             0.0% |‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| (2,761 octets, 2 fichiers)\n",
      "\n",
      "üìà R√âSUM√â DE L'√âVOLUTION HISTORIQUE DES LANGAGES\n",
      "================================================================================\n",
      "üèÜ LANGAGES LES PLUS UTILIS√âS (moyenne sur toutes les releases - bas√© sur octets):\n",
      "--------------------------------------------------------------------------------\n",
      "Langage      Moy %    Pr√©sence   Total octets    Total fichiers \n",
      "--------------------------------------------------------------------------------\n",
      "Python         83.1%     100%  314,859,080        21558\n",
      "HTML           10.1%     100%   39,921,004          682\n",
      "TypeScript      6.2%      12%    1,452,586          150\n",
      "Go              3.8%     100%   14,401,868          304\n",
      "C++             1.4%      50%    3,002,345          209\n",
      "Java            1.3%     100%    4,826,109          731\n",
      "C               0.2%     100%      744,481          207\n",
      "Swift           0.1%      75%      276,216           65\n",
      "C#              0.0%      88%       84,653           14\n",
      "JavaScript      0.0%      50%       24,519           10\n"
     ]
    }
   ],
   "source": [
    "# Remplacer votre cellule d'analyse par :\n",
    "selected_releases, historical_languages_data = get_complete_releases_analysis_historical(owner, repo_name, num_releases=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57d8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec2c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "584786a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordre chronologique des releases:\n",
      "  2016-02-16 (v0.6.0)\n",
      "  2017-06-30 (v1.2.1)\n",
      "  2018-11-05 (v1.12.0)\n",
      "  2020-01-26 (v1.15.2)\n",
      "  2021-08-10 (v2.5.1)\n",
      "  2022-11-18 (v2.11.0)\n",
      "  2024-03-08 (v2.15.1)\n",
      "  2025-08-13 (v2.20.0)\n",
      "\n",
      "Langages d√©tect√©s: ['C', 'C#', 'C++', 'CSS', 'Go', 'HTML', 'Java', 'JavaScript', 'Python', 'Swift', 'TypeScript']\n",
      "\n",
      "üîç MATRICE COMPL√àTE AVEC DATES:\n",
      "                   C        C#       C++       CSS        Go       HTML  \\\n",
      "Date                                                                      \n",
      "2016-02-16  0.159377  0.025055  0.398702  0.005092  4.012620  14.144968   \n",
      "2017-06-30  0.152685  0.000000  0.000000  0.003324  3.630310   4.901877   \n",
      "2018-11-05  0.102359  0.019011  0.000000  0.000000  2.821746  10.533962   \n",
      "2020-01-26  0.299022  0.015457  4.666739  0.000000  3.015164   8.449092   \n",
      "2021-08-10  0.299235  0.027101  0.003239  0.000000  4.064260   9.495694   \n",
      "2022-11-18  0.176277  0.027969  0.000000  0.000000  4.342703   9.726632   \n",
      "2024-03-08  0.182173  0.026892  0.000000  0.000000  4.313022   9.291289   \n",
      "2025-08-13  0.159803  0.025122  0.369128  0.005106  4.020144  14.182788   \n",
      "\n",
      "                Java  JavaScript     Python     Swift  TypeScript  \n",
      "Date                                                               \n",
      "2016-02-16  1.232500    0.005269  79.920859  0.095558    0.000000  \n",
      "2017-06-30  1.235910    0.060137  83.778406  0.000000    6.237351  \n",
      "2018-11-05  1.728249    0.000000  84.794674  0.000000    0.000000  \n",
      "2020-01-26  1.226504    0.000000  82.260114  0.067906    0.000000  \n",
      "2021-08-10  1.031782    0.000000  85.010163  0.068526    0.000000  \n",
      "2022-11-18  1.196495    0.000000  84.427481  0.102443    0.000000  \n",
      "2024-03-08  1.320842    0.009502  84.753985  0.102296    0.000000  \n",
      "2025-08-13  1.235795    0.005283  79.901017  0.095814    0.000000  \n",
      "\n",
      "üìä MATRICE DES LANGAGES PAR DATE DE RELEASE:\n",
      "====================================================================================================\n",
      "            C++   Go  HTML  Java  Python  TypeScript\n",
      "Date                                                \n",
      "2016-02-16  0.4  4.0  14.1   1.2    79.9         0.0\n",
      "2017-06-30  0.0  3.6   4.9   1.2    83.8         6.2\n",
      "2018-11-05  0.0  2.8  10.5   1.7    84.8         0.0\n",
      "2020-01-26  4.7  3.0   8.4   1.2    82.3         0.0\n",
      "2021-08-10  0.0  4.1   9.5   1.0    85.0         0.0\n",
      "2022-11-18  0.0  4.3   9.7   1.2    84.4         0.0\n",
      "2024-03-08  0.0  4.3   9.3   1.3    84.8         0.0\n",
      "2025-08-13  0.4  4.0  14.2   1.2    79.9         0.0\n",
      "\n",
      "Note: Seuls les langages avec au moins 1.0% dans au moins une release sont affich√©s.\n",
      "Langages filtr√©s: 5\n",
      "Matrice avec dates export√©e vers: languages_matrix_dates_tensorflow_tensorflow.csv\n",
      "\n",
      "üìà STATISTIQUES DE LA MATRICE AVEC DATES:\n",
      "P√©riode couverte: 2016-02-16 ‚Üí 2025-08-13\n",
      "Dimensions: 8 releases √ó 11 langages\n",
      "Langages avec pr√©sence > 0%: 65\n",
      "Langages dominants (>10% dans au moins une release): 2\n"
     ]
    }
   ],
   "source": [
    "def create_languages_matrix(historical_languages_data):\n",
    "    \"\"\"\n",
    "    Cr√©e une matrice DataFrame des langages par releases avec dates\n",
    "    \n",
    "    Args:\n",
    "        historical_languages_data (dict): Donn√©es des langages par release\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Matrice avec les dates en index et les langages en colonnes\n",
    "    \"\"\"\n",
    "    # Pr√©parer les donn√©es pour le graphique\n",
    "    release_data = []\n",
    "\n",
    "    # Collecter toutes les releases dans l'ordre chronologique avec leurs dates\n",
    "    for tag, data in historical_languages_data.items():\n",
    "        release_info = data['release_info']\n",
    "        date_str = release_info['published_at'] or release_info['created_at']\n",
    "        # Extraire seulement la date (YYYY-MM-DD)\n",
    "        date_only = date_str[:10]\n",
    "        release_data.append((date_str, date_only, tag, data))\n",
    "\n",
    "    # Trier par date\n",
    "    release_data.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Extraire les informations dans l'ordre chronologique\n",
    "    release_dates = [item[1] for item in release_data]  # Dates format√©es (YYYY-MM-DD)\n",
    "    release_tags = [item[2] for item in release_data]   # Tags correspondants\n",
    "    release_info_ordered = [item[3] for item in release_data]  # Donn√©es correspondantes\n",
    "\n",
    "    print(f\"Ordre chronologique des releases:\")\n",
    "    for date, tag in zip(release_dates, release_tags):\n",
    "        print(f\"  {date} ({tag})\")\n",
    "\n",
    "    # Collecter tous les langages uniques\n",
    "    all_languages = set()\n",
    "    for data in historical_languages_data.values():\n",
    "        all_languages.update(data['languages'].keys())\n",
    "\n",
    "    print(f\"\\nLangages d√©tect√©s: {sorted(all_languages)}\")\n",
    "\n",
    "    # Cr√©er la matrice avec pandas\n",
    "    matrix_data = {}\n",
    "    \n",
    "    for lang in sorted(all_languages):\n",
    "        percentages = []\n",
    "        for data in release_info_ordered:\n",
    "            if lang in data['languages']:\n",
    "                percentages.append(data['languages'][lang]['percentage'])\n",
    "            else:\n",
    "                percentages.append(0.0)  # 0% si le langage n'est pas pr√©sent\n",
    "        matrix_data[lang] = percentages\n",
    "\n",
    "    # Cr√©er le DataFrame avec les dates comme index et les langages comme colonnes\n",
    "    languages_matrix = pd.DataFrame(matrix_data, index=release_dates)\n",
    "    languages_matrix.index.name = 'Date'\n",
    "    \n",
    "    return languages_matrix\n",
    "\n",
    "def display_languages_matrix(languages_matrix, min_percentage=1.0):\n",
    "    \"\"\"\n",
    "    Affiche la matrice des langages avec dates et formatage am√©lior√©\n",
    "    \n",
    "    Args:\n",
    "        languages_matrix (pd.DataFrame): Matrice des langages avec dates\n",
    "        min_percentage (float): Pourcentage minimum pour afficher un langage\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä MATRICE DES LANGAGES PAR DATE DE RELEASE:\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Filtrer les langages avec un pourcentage significatif\n",
    "    significant_langs = languages_matrix.columns[languages_matrix.max() >= min_percentage]\n",
    "    filtered_matrix = languages_matrix[significant_langs]\n",
    "    \n",
    "    # Affichage format√©\n",
    "    print(filtered_matrix.round(1))\n",
    "    \n",
    "    print(f\"\\nNote: Seuls les langages avec au moins {min_percentage}% dans au moins une release sont affich√©s.\")\n",
    "    print(f\"Langages filtr√©s: {len(languages_matrix.columns) - len(significant_langs)}\")\n",
    "    \n",
    "    return filtered_matrix\n",
    "\n",
    "def export_languages_matrix(languages_matrix, filename=None):\n",
    "    \"\"\"\n",
    "    Exporte la matrice avec dates vers un fichier CSV\n",
    "    \n",
    "    Args:\n",
    "        languages_matrix (pd.DataFrame): Matrice des langages avec dates\n",
    "        filename (str): Nom du fichier (optionnel)\n",
    "    \n",
    "    Returns:\n",
    "        str: Chemin du fichier export√©\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        filename = f\"languages_matrix_dates_{owner}_{repo_name}.csv\"\n",
    "    \n",
    "    languages_matrix.to_csv(filename)\n",
    "    print(f\"Matrice avec dates export√©e vers: {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Utilisation des fonctions modifi√©es\n",
    "languages_matrix = create_languages_matrix(historical_languages_data)\n",
    "\n",
    "# Affichage de la matrice compl√®te avec dates\n",
    "print(\"\\nüîç MATRICE COMPL√àTE AVEC DATES:\")\n",
    "print(languages_matrix)\n",
    "\n",
    "# Affichage filtr√© (langages significatifs seulement)\n",
    "filtered_matrix = display_languages_matrix(languages_matrix, min_percentage=1.0)\n",
    "\n",
    "# Export vers CSV\n",
    "export_filename = export_languages_matrix(languages_matrix)\n",
    "\n",
    "# Statistiques sur la matrice\n",
    "print(f\"\\nüìà STATISTIQUES DE LA MATRICE AVEC DATES:\")\n",
    "print(f\"P√©riode couverte: {languages_matrix.index[0]} ‚Üí {languages_matrix.index[-1]}\")\n",
    "print(f\"Dimensions: {languages_matrix.shape[0]} releases √ó {languages_matrix.shape[1]} langages\")\n",
    "print(f\"Langages avec pr√©sence > 0%: {(languages_matrix > 0).sum().sum()}\")\n",
    "print(f\"Langages dominants (>10% dans au moins une release): {(languages_matrix > 10).any().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02196742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_repository(owner, repo_name, per_page=100, num_releases=8):\n",
    "    \"\"\"\n",
    "    R√©cup√®re la matrice des langages pour un repository donn√©\n",
    "    \n",
    "    Args:\n",
    "        owner (str): Propri√©taire du repository\n",
    "        repo_name (str): Nom du repository\n",
    "        per_page (int): Nombre de releases par page (max 100)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Matrice des langages avec dates\n",
    "    \"\"\"\n",
    "    # R√©cup√©rer toutes les releases\n",
    "    all_releases = get_time_spaced_releases_summary(owner, repo_name, num_releases=8)\n",
    "    if not all_releases:\n",
    "        print(f\"Aucune release trouv√©e pour {owner}/{repo_name}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    # Analyser les langages historiques\n",
    "    languages_analysis = analyze_all_releases_languages_historical(owner, repo_name, all_releases)\n",
    "    \n",
    "    # Cr√©er la matrice avec dates\n",
    "    languages_matrix = create_languages_matrix(languages_analysis)\n",
    "    \n",
    "    return languages_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff935c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
